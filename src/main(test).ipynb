{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Informacje o projekcie\n",
    "- **Autorzy:** Bartłomiej Rydzak, Mateusz Adamczyk, Michał Saturczak\n",
    "- **Temat:** Kompresja danych z użyciem SSN"
   ]
  },
  {
   "cell_type": "raw",
   "id": "310dfaa0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import kagglehub\n",
    "\n",
    "print(\"Biblioteki załadowane pomyślnie\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55f551ad",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def file_exists(filepath: str) -> bool:\n",
    "    return Path(filepath).exists()\n",
    "\n",
    "def delete_file(filepath: str):\n",
    "    try:\n",
    "        Path(filepath).unlink()\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "def run_shell(command: str) -> int:\n",
    "    return os.system(command)\n",
    "\n",
    "print(\"Funkcje pomocnicze zdefiniowane\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfa7b01a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Ładowanie danych EKG\n",
    "\n",
    "Funkcja do automatycznego pobierania datasetu z Kaggle lub ładowania z lokalnych plików. Dataset zawiera sygnały EKG z różnymi arytmiami z bazy MIT-BIH.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33042c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ecg_dataset():\n",
    "    try:\n",
    "        dataset_path = Path(kagglehub.dataset_download(\"shayanfazeli/heartbeat\"))\n",
    "        print(f\"Dataset path: {dataset_path}\")\n",
    "        \n",
    "        train_data = pd.read_csv(dataset_path / 'mitbih_train.csv', header=None)\n",
    "        test_data = pd.read_csv(dataset_path / 'mitbih_test.csv', header=None)\n",
    "        abnormal_data = pd.read_csv(dataset_path / 'ptbdb_abnormal.csv', header=None)\n",
    "        normal_data = pd.read_csv(dataset_path / 'ptbdb_normal.csv', header=None)\n",
    "        \n",
    "        print(\"Dane pobrane z Kaggle pomyślnie!\")\n",
    "        \n",
    "    except Exception as err:\n",
    "        print(f\"Pobieranie nie powiodło się: {err}\")\n",
    "        print(\"Przechodzę do lokalnych plików lub rozpakowywania 7z...\")\n",
    "        \n",
    "        if not file_exists(\"mitbih_test.csv\"):\n",
    "            success = any(run_shell(cmd) == 0 for cmd in [\"7za e data.7z.001\", \"7z e data.7z.001\", \"7zz e data.7z.001\"])\n",
    "            if not success:\n",
    "                print(\"Zainstaluj 7za lub 7z, by rozpakować archiwum.\")\n",
    "        \n",
    "        train_data = pd.read_csv('mitbih_train.csv', header=None)\n",
    "        test_data = pd.read_csv('mitbih_test.csv', header=None)\n",
    "        abnormal_data = pd.read_csv('ptbdb_abnormal.csv', header=None)\n",
    "        normal_data = pd.read_csv('ptbdb_normal.csv', header=None)\n",
    "        \n",
    "        print(\"Dane załadowane z lokalnych plików!\")\n",
    "        \n",
    "    return train_data, test_data, abnormal_data, normal_data\n",
    "\n",
    "print(\"Funkcja ładowania danych zdefiniowana\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46f81b50",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Przygotowanie i przetwarzanie danych\n",
    "\n",
    "Funkcje do przygotowania danych do treningu - ekstrakcja normalnych i anormalnych sygnałów EKG oraz normalizacja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df: pd.DataFrame, label_value: int):\n",
    "    subset = df[df[187] == label_value]\n",
    "    features = subset.iloc[:, :187].values.astype(np.float32)\n",
    "    labels = subset[187].values.tolist()\n",
    "    return features, labels\n",
    "\n",
    "def normalize(train_arr, test_arr):\n",
    "    min_val = np.min(train_arr, axis=(0,1))\n",
    "    max_val = np.max(train_arr, axis=(0,1))\n",
    "    train_norm = (train_arr - min_val) / (max_val - min_val)\n",
    "    test_norm = (test_arr - min_val) / (max_val - min_val)\n",
    "    return train_norm, test_norm\n",
    "\n",
    "print(\"Funkcje przetwarzania danych zdefiniowane\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cae80dfb",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Wizualizacja sygnałów EKG\n",
    "\n",
    "Funkcja do generowania wykresów porównawczych normalnych i anormalnych sygnałów EKG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ecg_samples(normal_signals, abnormal_signals):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "    for idx in range(8):\n",
    "        plt.subplot(4, 4, idx+1)\n",
    "        plt.plot(normal_signals[idx])\n",
    "        plt.title(f\"Normal ECG Sample {idx+1}\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        \n",
    "    for idx in range(8, 16):\n",
    "        plt.subplot(4, 4, idx+1)\n",
    "        plt.plot(abnormal_signals[idx])\n",
    "        plt.title(f\"Abnormal ECG Sample {idx-7}\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ecg_samples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_errors(epochs, errors):\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, errors)\n",
    "    plt.title(\"Error During Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Validation RMSE\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_error.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Funkcje wizualizacji zdefiniowane\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c49e186",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Definicja modelu autokodera (MLP)\n",
    "\n",
    "Architektura sieci neuronowej do kompresji sygnałów EKG:\n",
    "- **Encoder**: 187 → 100 → 40 → 20 (kompresja)\n",
    "- **Decoder**: 20 → 40 → 100 → 187 (rekonstrukcja)\n",
    "\n",
    "Model wykorzystuje transformacje nieliniowe przed enkodowaniem i po dekodowaniu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGAutoEncoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ECGAutoEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(100, activation='relu', input_shape=(188,)),\n",
    "            tf.keras.layers.Dense(40, activation='relu'),\n",
    "            tf.keras.layers.Dense(20, activation='linear')\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(40, activation='relu', input_shape=(20,)),\n",
    "            tf.keras.layers.Dense(100, activation='relu'),\n",
    "            tf.keras.layers.Dense(188, activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return decoded\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(tf.sqrt(x))\n",
    "    \n",
    "    def decode(self, encoded):\n",
    "        return tf.square(self.decoder(encoded))\n",
    "\n",
    "print(\"Model autokodera zdefiniowany\")\n",
    "print(\"Stopień kompresji: 187 → 20 wymiarów (9.35x mniej danych)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "353784a6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Trening modelu\n",
    "\n",
    "Konfiguracja i pętla treningowa z wczesnym zatrzymaniem i monitorowaniem postępu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ec11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataset, val_data, loss_fn):\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(dataset).shuffle(1000).batch(250)\n",
    "    \n",
    "    for batch in train_ds:\n",
    "        with tf.GradientTape() as tape:\n",
    "            recon = model(batch)\n",
    "            loss = loss_fn(batch, recon)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    val_recon = model(val_data)\n",
    "    val_loss = tf.reduce_mean(tf.sqrt(tf.reduce_mean(tf.square(val_recon - val_data), axis=1)))\n",
    "    return float(val_loss)\n",
    "\n",
    "print(\"Funkcja treningu zdefiniowana\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9847d36d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Główny eksperyment - ładowanie i przygotowanie danych\n",
    "\n",
    "Uruchamiamy główny kod eksperymentu - ładujemy dane i przygotowujemy je do treningu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ładowanie danych EKG...\")\n",
    "train_df, test_df, abn_df, norm_df = load_ecg_dataset()\n",
    "\n",
    "print(\"Przygotowanie danych...\")\n",
    "x_train, y_train = prepare_data(train_df, label_value=0)\n",
    "x_test, y_test = prepare_data(test_df, label_value=0)\n",
    "\n",
    "print(f\"Dane treningowe: {x_train.shape}\")\n",
    "print(f\"Dane testowe: {x_test.shape}\")\n",
    "\n",
    "abnormal_samples, _ = prepare_data(test_df, label_value=1)\n",
    "plot_ecg_samples(x_test, abnormal_samples)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9037f60",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Normalizacja i przygotowanie modelu\n",
    "\n",
    "Normalizujemy dane i przygotowujemy model do treningu z odpowiednim optimizerem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a490e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Normalizacja danych...\")\n",
    "train_norm, test_norm = normalize(train_df.values.astype(np.float32), test_df.values.astype(np.float32))\n",
    "\n",
    "print(f\"Znormalizowane dane treningowe: {train_norm.shape}\")\n",
    "print(f\"Zakres danych po normalizacji: [{train_norm.min():.3f}, {train_norm.max():.3f}]\")\n",
    "\n",
    "print(\"Inicjalizacja modelu...\")\n",
    "model = ECGAutoEncoder()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "print(\"Model i optimizer gotowe do treningu\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7735b0d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Pętla treningowa z wczesnym zatrzymaniem\n",
    "\n",
    "Trening z monitorowaniem walidacji i mechanizmem wczesnego zatrzymania dla uniknięcia overfittingu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f53dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rozpoczynanie treningu...\")\n",
    "\n",
    "epochs = []\n",
    "errors = []\n",
    "error = 1.0\n",
    "no_improve_count = 0\n",
    "best_weights = None\n",
    "epoch = 1\n",
    "\n",
    "target_error = 8.6e-3\n",
    "max_epochs = 200\n",
    "patience = 15\n",
    "\n",
    "print(f\"Cel: RMSE < {target_error}\")\n",
    "print(f\"Maksymalne epoki: {max_epochs}\")\n",
    "print(f\"Cierpliwość: {patience} epok bez poprawy\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "while error > target_error and epoch <= max_epochs and no_improve_count < patience:\n",
    "    val_error = train_epoch(model, optimizer, train_norm, test_norm, loss_function)\n",
    "    \n",
    "    diff = error - val_error\n",
    "    if diff < 1e-6:\n",
    "        no_improve_count += 1\n",
    "    else:\n",
    "        no_improve_count = 0\n",
    "        best_weights = model.get_weights()\n",
    "    \n",
    "    error = val_error\n",
    "    epochs.append(epoch)\n",
    "    errors.append(error)\n",
    "    \n",
    "    status = \"🔴\" if no_improve_count > 0 else \"🟢\"\n",
    "    print(f\"{status} Epoch {epoch:3d} | RMSE: {error:.6f} | Diff: {diff:.6f} | No improve: {no_improve_count}\")\n",
    "    \n",
    "    epoch += 1\n",
    "\n",
    "if best_weights:\n",
    "    model.set_weights(best_weights)\n",
    "    print(f\"Przywrócono najlepsze wagi z epoki {epoch - no_improve_count - 1}\")\n",
    "\n",
    "print(f\"\\nTrening zakończony po {epoch-1} epokach\")\n",
    "print(f\"Końcowy RMSE: {error:.6f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f9e39a2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Wizualizacja wyników treningu\n",
    "\n",
    "Wyświetlamy krzywą uczenia się modelu podczas treningu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114085d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(epochs) > 1:\n",
    "    plot_training_errors(epochs, errors)\n",
    "else:\n",
    "    print(\"Uczenie zbyt szybkie, brak wykresu\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5b2c7a3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Ewaluacja końcowa modelu\n",
    "\n",
    "Ocena jakości kompresji i rekonstrukcji sygnałów EKG na danych treningowych i testowych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ewaluacja końcowa modelu...\")\n",
    "\n",
    "compressed_train = model.encode(train_norm)\n",
    "compressed_test = model.encode(test_norm)\n",
    "decompressed_train = model.decode(compressed_train)\n",
    "decompressed_test = model.decode(compressed_test)\n",
    "\n",
    "train_rmse = float(tf.reduce_mean(tf.sqrt(tf.reduce_mean(tf.square(train_norm - decompressed_train), axis=1))))\n",
    "test_rmse = float(tf.reduce_mean(tf.sqrt(tf.reduce_mean(tf.square(test_norm - decompressed_test), axis=1))))\n",
    "\n",
    "print(f\"Końcowy błąd treningowy (RMSE): {train_rmse:.6f}\")\n",
    "print(f\"Końcowy błąder testowy (RMSE): {test_rmse:.6f}\")\n",
    "print(f\"Stopień kompresji: {187/20:.1f}x (187 → 20 wymiarów)\")\n",
    "\n",
    "print(\"\\nGenerowanie porównania oryginału z rekonstrukcją...\")\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(test_norm[0], label='Oryginalny sygnał', linewidth=2)\n",
    "plt.plot(decompressed_test[0].numpy(), label='Odtworzony sygnał', linewidth=2, alpha=0.8)\n",
    "plt.title(\"Porównanie oryginału i rekonstrukcji EKG\", fontsize=14)\n",
    "plt.xlabel(\"Próbka\")\n",
    "plt.ylabel(\"Amplituda (znormalizowana)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('reconstruction_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b13cb17",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Analiza rozkładu błędów\n",
    "\n",
    "Statystyczna analiza błędów rekonstrukcji dla lepszego zrozumienia wydajności modelu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2497b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analiza rozkładu błędów rekonstrukcji...\")\n",
    "\n",
    "train_err_flat = (decompressed_train - train_norm).numpy().flatten()\n",
    "test_err_flat = (decompressed_test - test_norm).numpy().flatten()\n",
    "\n",
    "print(f\"Błędy treningowe - średnia: {train_err_flat.mean():.6f}, std: {train_err_flat.std():.6f}\")\n",
    "print(f\"Błędy testowe - średnia: {test_err_flat.mean():.6f}, std: {test_err_flat.std():.6f}\")\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_err_flat, bins=50, log=True, alpha=0.7, color='blue')\n",
    "plt.title(\"Rozkład błędów treningowych (log scale)\")\n",
    "plt.xlabel(\"Błąd rekonstrukcji\")\n",
    "plt.ylabel(\"Częstość (log)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(test_err_flat, bins=50, log=True, alpha=0.7, color='red')\n",
    "plt.title(\"Rozkład błędów testowych (log scale)\")\n",
    "plt.xlabel(\"Błąd rekonstrukcji\")\n",
    "plt.ylabel(\"Częstość (log)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('error_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25a793c6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Sprzątanie i podsumowanie\n",
    "\n",
    "Ostatnie operacje - sprzątanie plików tymczasowych i podsumowanie wyników eksperymentu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eced93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sprzątanie...\")\n",
    "\n",
    "try:\n",
    "    if 'dataset_path' not in locals():\n",
    "        files_to_clean = [\"mitbih_test.csv\", \"mitbih_train.csv\", \"ptbdb_abnormal.csv\", \"ptbdb_normal.csv\"]\n",
    "        for f in files_to_clean:\n",
    "            if file_exists(f):\n",
    "                delete_file(f)\n",
    "                print(f\"Usunięto {f}\")\n",
    "        print(\"Lokalne pliki CSV posprzątane\")\n",
    "    else:\n",
    "        print(\"Dane pobrane z Kaggle - brak konieczności sprzątania\")\n",
    "except Exception as e:\n",
    "    print(f\"Błąd podczas sprzątania: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PODSUMOWANIE EKSPERYMENTU KOMPRESJI EKG\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Architektura: 187 → 100 → 40 → 20 → 40 → 100 → 187\")\n",
    "print(f\"Stopień kompresji: {187/20:.1f}x\")\n",
    "print(f\"RMSE treningowy: {train_rmse:.6f}\")\n",
    "print(f\"RMSE testowy: {test_rmse:.6f}\")\n",
    "print(f\"Liczba epok: {len(epochs)}\")\n",
    "print(f\"Pliki wygenerowane:\")\n",
    "print(\"   - ecg_samples.png (przykładowe sygnały)\")\n",
    "print(\"   - training_error.png (krzywa uczenia)\")\n",
    "print(\"   - reconstruction_comparison.png (porównanie)\")\n",
    "print(\"   - error_distribution.png (rozkład błędów)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Eksperyment zakończony pomyślnie!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
